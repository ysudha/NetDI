{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 104)\n",
      "(46, 312)\n"
     ]
    }
   ],
   "source": [
    "# data augmentation. This code performs kfold=5\n",
    "# ta503 CSM data\n",
    "# my data from a mat file: first 6 rows = VN lang positive. next \n",
    "# 17 rows = language negative\n",
    "# DI features = 104, \n",
    "# indeg features = 104\n",
    "# outdeg features = 104\n",
    "# Kcores features = 104\n",
    "# power features = 104\n",
    "# edge betweenness features = 104\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "X = scipy.io.loadmat('X_ta503.mat',struct_as_record=False)\n",
    "X_total = X['X']\n",
    "y=np.array([0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\n",
    "y=y.T\n",
    "\n",
    "npos=6\n",
    "nneg = 17\n",
    "#DI features\n",
    "Xtemp = X_total[:,0:104] #original DI matrix\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "XDI = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented DI matrix\n",
    "print(XDI.shape)\n",
    "\n",
    "#indeg features\n",
    "Xtemp = X_total[:,104:208]\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "X_indeg = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented matrix\n",
    "\n",
    "#outdeg features\n",
    "Xtemp = X_total[:,208:312]\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "X_outdeg = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented matrix\n",
    "\n",
    "#indeg and outdeg features combined\n",
    "X_in_out_deg = np.concatenate((X_indeg,X_outdeg),axis=1)\n",
    "\n",
    "#Kcores features\n",
    "Xtemp = X_total[:,312:416]\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "X_kcores = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented matrix\n",
    "\n",
    "#power features\n",
    "Xtemp = X_total[:,416:520]\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "X_power = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented matrix\n",
    "\n",
    "#edge features\n",
    "Xtemp = X_total[:,520:624]\n",
    "X1 = Xtemp[0:npos,0:52]\n",
    "X2 = Xtemp[0:npos,52:104]\n",
    "Xnew = np.concatenate((X2,X1),axis=1) #interchange the node order\n",
    "X1n = Xtemp[npos:npos+nneg,0:52]\n",
    "X2n = Xtemp[npos:npos+nneg,52:104]\n",
    "Xnew_n = np.concatenate((X2n,X1n),axis=1) #interchange the node order\n",
    "X_edge = np.concatenate((Xnew,Xtemp,Xnew_n),axis=0) #augmented matrix\n",
    "\n",
    "#kcores and edge features combined\n",
    "X_kcores_edge = np.concatenate((X_kcores,X_edge),axis=1)\n",
    "\n",
    "#kcores and power combined\n",
    "X_kcores_power = np.concatenate((X_kcores,X_power),axis=1)\n",
    "\n",
    "#Edge and power combined\n",
    "X_edge_power = np.concatenate((X_edge,X_power),axis=1)\n",
    "\n",
    "#kcores+ edge + power combined\n",
    "X_kcores_edge_power = np.concatenate((X_kcores_edge,X_power),axis=1)\n",
    "\n",
    "#In + power combined\n",
    "X_In_power = np.concatenate((X_indeg,X_power),axis=1)\n",
    "\n",
    "#Out + power combined\n",
    "X_Out_power = np.concatenate((X_outdeg,X_power),axis=1)\n",
    "\n",
    "#InOut + power combined\n",
    "X_InOut_power = np.concatenate((X_in_out_deg,X_power),axis=1)\n",
    "\n",
    "# Inout+Kcores+power\n",
    "X_InOut_kcores_power = np.concatenate((X_in_out_deg,X_kcores_power),axis=1)\n",
    "\n",
    "nElements,pFeatures = X_kcores_edge_power.shape\n",
    "\n",
    "print(X_kcores_edge_power.shape)\n",
    "#imshow(X_power)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sudhayellapantula/opt/anaconda3/envs/langCSM/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# original Code source: Gaël Varoquaux\n",
    "#              Andreas Müller\n",
    "# Modified for classification for CSM data by Sudha Yellapantula\n",
    "# License: BSD 3 clause\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold,StratifiedKFold # import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import balanced_accuracy_score, average_precision_score, precision_score, recall_score,confusion_matrix\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "nClassifiers = 4\n",
    "nDataSets = 11\n",
    "maxRep=100\n",
    "n_splits=5\n",
    "\n",
    "predictions = np.zeros((nClassifiers,nDataSets, nElements, maxRep))\n",
    "prec = np.zeros((nClassifiers,nDataSets,n_splits,maxRep))\n",
    "recall = np.zeros((nClassifiers,nDataSets,n_splits,maxRep))\n",
    "bal_acc = np.zeros((nClassifiers,nDataSets,n_splits,maxRep))\n",
    "tnr = np.zeros((nClassifiers,nDataSets,n_splits,maxRep))\n",
    "for indRep in range(0,maxRep):\n",
    "\n",
    "    classifiers = [\n",
    "       KNeighborsClassifier(3),\n",
    "        LinearSVC(C=0.000001, class_weight='balanced', dual=True, fit_intercept=False,\n",
    "         intercept_scaling=1, loss='squared_hinge', max_iter=10000,\n",
    "         multi_class='ovr', penalty='l2', random_state=None, tol=0.0000001,\n",
    "         verbose=0),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0),random_state=None),\n",
    "        DecisionTreeClassifier(max_depth=20,random_state=None)\n",
    "    ]\n",
    "\n",
    "    Power_features = (X_power,y)\n",
    "    Indeg_features = (X_indeg,y)\n",
    "    Outdeg_features = (X_outdeg,y)\n",
    "    In_out_deg_features = (X_in_out_deg,y)\n",
    "    Kcores_features = (X_kcores,y)\n",
    "    Kcores_power_features = (X_kcores_power,y)\n",
    "    In_power_features = (X_In_power,y)\n",
    "    Out_power_features = (X_Out_power,y)\n",
    "    InOut_power_features = (X_InOut_power,y)\n",
    "    Kcores_In_Out_power_features = (X_InOut_kcores_power,y)\n",
    "\n",
    "    datasets = [Power_features,\n",
    "                Indeg_features,\n",
    "                Outdeg_features,\n",
    "                In_out_deg_features,\n",
    "                Kcores_features,\n",
    "                Kcores_power_features,\n",
    "                In_power_features,\n",
    "                Out_power_features,\n",
    "                InOut_power_features,\n",
    "                Kcores_In_Out_power_features\n",
    "                ]\n",
    "\n",
    "    #predictions = np.zeros((len(classifiers),len(datasets), nElements))\n",
    "    kf = StratifiedKFold(n_splits=5,random_state=None, shuffle=True)\n",
    "    ic,ids,ie=0,0,0 #counter index for classifier, dataset and element\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        # iterate over datasets\n",
    "        ids=0\n",
    "        for ds_cnt, ds in enumerate(datasets):\n",
    "            # preprocess dataset, split into training and test part\n",
    "            X, y = ds\n",
    "            #X,y = RandomSubSampler(X,y)\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "            ie=0\n",
    "            for train_index, test_index in kf.split(X,y):\n",
    "                X_train, X_test = X[train_index,:], X[test_index,:]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                clf.fit(X_train, y_train)\n",
    "                score = clf.score(X_test, y_test)\n",
    "                #predictions[ic,ids,ie,indRep]=score\n",
    "                y_pred = clf.predict(X_test)\n",
    "                CM = confusion_matrix(y_test, y_pred)\n",
    "                TN = CM[0][0]\n",
    "                FN = CM[1][0]\n",
    "                TP = CM[1][1]\n",
    "                FP = CM[0][1]\n",
    "                bal_acc[ic,ids,ie,indRep]= balanced_accuracy_score(y_test, y_pred)\n",
    "                prec[ic,ids,ie,indRep]= precision_score(y_test, y_pred)\n",
    "                recall[ic,ids,ie,indRep]= recall_score(y_test, y_pred)\n",
    "                tnr[ic,ids,ie,indRep]= np.true_divide(TN, (TN + FP))\n",
    "                ie +=1\n",
    "            ids +=1\n",
    "        ic +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy\n",
      " [[0.752 0.587 0.685 0.696]\n",
      " [0.659 0.765 0.732 0.718]\n",
      " [0.588 0.791 0.661 0.69 ]\n",
      " [0.608 0.788 0.632 0.665]\n",
      " [0.672 0.794 0.558 0.786]\n",
      " [0.825 0.778 0.759 0.695]\n",
      " [0.859 0.747 0.728 0.641]\n",
      " [0.786 0.752 0.614 0.652]\n",
      " [0.846 0.788 0.72  0.638]\n",
      " [0.727 0.791 0.735 0.639]]\n",
      "ste of accuracy\n",
      " [[0.014 0.014 0.013 0.016]\n",
      " [0.013 0.008 0.015 0.014]\n",
      " [0.014 0.007 0.017 0.014]\n",
      " [0.016 0.007 0.017 0.014]\n",
      " [0.015 0.007 0.012 0.013]\n",
      " [0.013 0.011 0.013 0.014]\n",
      " [0.012 0.013 0.014 0.014]\n",
      " [0.012 0.013 0.014 0.015]\n",
      " [0.012 0.007 0.015 0.014]\n",
      " [0.015 0.008 0.014 0.014]]\n",
      "mean precision\n",
      " [[0.877 0.8   0.831 0.85 ]\n",
      " [0.813 0.994 0.854 0.879]\n",
      " [0.792 1.    0.829 0.85 ]\n",
      " [0.798 1.    0.803 0.841]\n",
      " [0.839 1.    0.771 0.915]\n",
      " [0.922 0.971 0.875 0.851]\n",
      " [0.94  0.943 0.867 0.82 ]\n",
      " [0.931 0.952 0.807 0.825]\n",
      " [0.941 0.996 0.863 0.822]\n",
      " [0.862 0.998 0.864 0.823]]\n",
      "ste of precision\n",
      " [[0.009 0.01  0.008 0.01 ]\n",
      " [0.007 0.007 0.009 0.009]\n",
      " [0.01  0.    0.011 0.009]\n",
      " [0.009 0.    0.01  0.009]\n",
      " [0.01  0.    0.008 0.009]\n",
      " [0.008 0.007 0.008 0.009]\n",
      " [0.007 0.01  0.009 0.01 ]\n",
      " [0.008 0.009 0.009 0.009]\n",
      " [0.007 0.006 0.009 0.009]\n",
      " [0.009 0.004 0.009 0.009]]\n",
      "mean recall\n",
      " [[0.866 0.653 0.94  0.856]\n",
      " [0.967 0.529 0.954 0.776]\n",
      " [0.739 0.583 0.871 0.821]\n",
      " [0.843 0.577 0.978 0.794]\n",
      " [0.799 0.588 0.915 0.825]\n",
      " [0.879 0.608 0.919 0.842]\n",
      " [0.887 0.591 0.864 0.791]\n",
      " [0.748 0.588 0.905 0.828]\n",
      " [0.862 0.576 0.862 0.804]\n",
      " [0.895 0.582 0.903 0.797]]\n",
      "ste of recall\n",
      " [[0.011 0.016 0.008 0.012]\n",
      " [0.006 0.016 0.007 0.014]\n",
      " [0.016 0.015 0.013 0.012]\n",
      " [0.012 0.015 0.007 0.012]\n",
      " [0.013 0.014 0.011 0.011]\n",
      " [0.01  0.016 0.009 0.012]\n",
      " [0.011 0.018 0.011 0.014]\n",
      " [0.014 0.017 0.011 0.012]\n",
      " [0.012 0.014 0.011 0.013]\n",
      " [0.011 0.015 0.01  0.014]]\n",
      "mean tnr/specificity\n",
      " [[0.637 0.52  0.43  0.537]\n",
      " [0.351 1.    0.51  0.66 ]\n",
      " [0.437 1.    0.451 0.558]\n",
      " [0.374 1.    0.286 0.536]\n",
      " [0.545 1.    0.201 0.747]\n",
      " [0.771 0.948 0.599 0.549]\n",
      " [0.831 0.903 0.591 0.49 ]\n",
      " [0.824 0.917 0.323 0.475]\n",
      " [0.831 1.    0.579 0.473]\n",
      " [0.56  1.    0.568 0.481]]\n",
      "ste of tnr/specificity\n",
      " [[0.026 0.025 0.029 0.031]\n",
      " [0.025 0.    0.03  0.028]\n",
      " [0.027 0.    0.034 0.028]\n",
      " [0.028 0.    0.034 0.029]\n",
      " [0.028 0.    0.027 0.027]\n",
      " [0.025 0.012 0.027 0.029]\n",
      " [0.02  0.016 0.028 0.027]\n",
      " [0.021 0.016 0.032 0.029]\n",
      " [0.02  0.    0.028 0.029]\n",
      " [0.029 0.    0.028 0.029]]\n"
     ]
    }
   ],
   "source": [
    "#for each rep, calculate these parameters\n",
    "np.set_printoptions(precision=3)\n",
    "prec_final = np.zeros((len(datasets),len(classifiers)))\n",
    "tnrate = np.zeros((len(datasets),len(classifiers)))\n",
    "rec = np.zeros((len(datasets),len(classifiers)))\n",
    "acc = np.zeros((len(datasets),len(classifiers)))\n",
    "\n",
    "\n",
    "ste_prec = np.zeros((len(datasets),len(classifiers)))\n",
    "ste_tnrate = np.zeros((len(datasets),len(classifiers)))\n",
    "ste_rec = np.zeros((len(datasets),len(classifiers)))\n",
    "ste_acc = np.zeros((len(datasets),len(classifiers)))\n",
    "\n",
    "for i in range(0,len(datasets)):\n",
    "    for j in range(0,len(classifiers)):\n",
    "        tnrate[i,j] = np.mean(tnr[j,i,:,:])\n",
    "        prec_final[i,j] = np.mean(prec[j,i,:,:])\n",
    "        rec[i,j] = np.mean(recall[j,i,:,:])\n",
    "        acc[i,j] = np.mean(bal_acc[j,i,:,:])\n",
    "        \n",
    "for i in range(0,len(datasets)):\n",
    "    for j in range(0,len(classifiers)):     \n",
    "        ste_tnrate[i,j] = 1.96*np.true_divide(np.std(tnr[j,i,:,:]),np.sqrt(maxRep*n_splits))\n",
    "        ste_prec[i,j] = 1.96*np.true_divide(np.std(prec[j,i,:,:]),np.sqrt(maxRep*n_splits))\n",
    "        ste_rec[i,j] = 1.96*np.true_divide(np.std(recall[j,i,:,:]),np.sqrt(maxRep*n_splits))\n",
    "        ste_acc[i,j] = 1.96*np.true_divide(np.std(bal_acc[j,i,:,:]),np.sqrt(maxRep*n_splits))\n",
    "\n",
    "    \n",
    "\n",
    "print(\"mean accuracy\\n\",acc)\n",
    "print(\"ste of accuracy\\n\",ste_acc)\n",
    "print(\"mean precision\\n\",prec_final)\n",
    "print(\"ste of precision\\n\",ste_prec)\n",
    "print(\"mean recall\\n\",rec)\n",
    "print(\"ste of recall\\n\",ste_rec)\n",
    "print(\"mean tnr/specificity\\n\",tnrate)\n",
    "print(\"ste of tnr/specificity\\n\",ste_tnrate)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
